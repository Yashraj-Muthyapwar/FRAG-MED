{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRAG-MED: Dynamic Federated Hospital Splitting\n",
    "\n",
    "**Dynamic Features:**\n",
    "- **User Configurable:** Set the exact number of hospitals and top conditions.\n",
    "- **Data-Driven Specialization:** Automatically assigns the most prevalent conditions in your dataset to hospitals.\n",
    "- **Affinity Matching:** Routes patients to the hospital that best fits their specific medical history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ‚öôÔ∏è DYNAMIC CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# How many hospitals do you want to create?\n",
    "NUM_HOSPITALS = 10\n",
    "\n",
    "# How many top conditions should drive the specialization?\n",
    "# (e.g., if 20, the top 20 conditions will be distributed among the hospitals)\n",
    "TOP_CONDITIONS_LIMIT = 10\n",
    "\n",
    "# Directories\n",
    "SOURCE_DIR = '../data/raw_patients' # Path to the directory containing the patient data \n",
    "DEST_DIR = '../data/federated_hospitals' # Path to the directory where the hospitals will be created\n",
    "\n",
    "print(f\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Generating {NUM_HOSPITALS} hospitals\")\n",
    "print(f\"   Using Top {TOP_CONDITIONS_LIMIT} conditions for specialization\")\n",
    "print(f\"   Source: {SOURCE_DIR}\")\n",
    "print(f\"   Destination: {DEST_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Data & Generate Dynamic Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conditions(json_data):\n",
    "    \"\"\"Extract simple condition list from patient file.\"\"\"\n",
    "    extracted = []\n",
    "    try:\n",
    "        if isinstance(json_data, dict) and 'encounters' in json_data:\n",
    "            for enc in json_data['encounters']:\n",
    "                for cond in enc.get('conditions', []):\n",
    "                    if 'code' in cond:\n",
    "                        extracted.append((cond['code'], cond.get('display_text', 'Unknown')))\n",
    "    except:\n",
    "        pass\n",
    "    return extracted\n",
    "\n",
    "def analyze_and_generate_profiles(source_dir, num_hospitals, top_n_conditions):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 1: ANALYZING & GENERATING PROFILES\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 1. Scan all files to find Top Conditions\n",
    "    if not os.path.exists(source_dir):\n",
    "        raise FileNotFoundError(f\"‚ùå Source directory {source_dir} not found!\")\n",
    "    \n",
    "    files = [f for f in os.listdir(source_dir) if f.endswith('.json')]\n",
    "    print(f\"üìã Scanning {len(files)} files for conditions...\")\n",
    "\n",
    "    global_condition_counts = Counter()\n",
    "    condition_names = {}\n",
    "    patient_data = {}\n",
    "\n",
    "    for filename in tqdm(files, desc=\"Analyzing\"):\n",
    "        filepath = os.path.join(source_dir, filename)\n",
    "        p_id = filename.replace('.json', '')\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        conditions = extract_conditions(data)\n",
    "        \n",
    "        # Store patient profile\n",
    "        patient_weights = Counter()\n",
    "        for code, name in conditions:\n",
    "            global_condition_counts[code] += 1\n",
    "            condition_names[code] = name\n",
    "            patient_weights[code] += 1 # Base weight\n",
    "        \n",
    "        # Boost weights for recurring conditions\n",
    "        final_weights = {k: v * (2.0 if v > 1 else 1.0) for k, v in patient_weights.items()}\n",
    "        \n",
    "        patient_data[p_id] = {\n",
    "            'filename': filename,\n",
    "            'weights': final_weights\n",
    "        }\n",
    "\n",
    "    # 2. Select Top Conditions for Specialization\n",
    "    top_conditions = [code for code, _ in global_condition_counts.most_common(top_n_conditions)]\n",
    "    print(f\"\\n‚úÖ Identified top {len(top_conditions)} prevalent conditions.\")\n",
    "\n",
    "    # 3. Distribute Conditions to Hospitals\n",
    "    # We split the top conditions list into chunks, one for each hospital\n",
    "    hospital_profiles = {}\n",
    "    chunk_size = len(top_conditions) // num_hospitals\n",
    "    remainder = len(top_conditions) % num_hospitals\n",
    "    \n",
    "    start_idx = 0\n",
    "    sizes = ['large', 'medium', 'small']\n",
    "    \n",
    "    for i in range(num_hospitals):\n",
    "        # Determine chunk size for this hospital\n",
    "        current_chunk = chunk_size + (1 if i < remainder else 0)\n",
    "        end_idx = start_idx + current_chunk\n",
    "        \n",
    "        assigned_conditions = top_conditions[start_idx:end_idx]\n",
    "        start_idx = end_idx\n",
    "        \n",
    "        # Create Profile\n",
    "        h_id = f\"hospital_{chr(65+i)}\" # Hospital_A, Hospital_B...\n",
    "        \n",
    "        # Assign random size\n",
    "        size = sizes[i % len(sizes)]\n",
    "        \n",
    "        # Create affinities (high score for assigned conditions)\n",
    "        affinities = {code: 3.0 for code in assigned_conditions}\n",
    "        \n",
    "        # Generate a display name for the specialization based on the first condition\n",
    "        if assigned_conditions:\n",
    "            primary_name = condition_names[assigned_conditions[0]].split('(')[0].strip()\n",
    "            specialization = f\"{primary_name} & General\"\n",
    "        else:\n",
    "            specialization = \"General Care\"\n",
    "\n",
    "        hospital_profiles[h_id] = {\n",
    "            'size': size,\n",
    "            'specialization_name': specialization,\n",
    "            'affinities': affinities\n",
    "        }\n",
    "        \n",
    "        print(f\"   üè• {h_id} ({size.upper()}): {specialization}\")\n",
    "        print(f\"      Focus: {[condition_names[c][:20] for c in assigned_conditions]}\")\n",
    "\n",
    "    return patient_data, hospital_profiles, condition_names\n",
    "\n",
    "# Execute Analysis\n",
    "patient_data, HOSPITAL_PROFILES, condition_names = analyze_and_generate_profiles(SOURCE_DIR, NUM_HOSPITALS, TOP_CONDITIONS_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assignment Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_affinity_score(patient_weights, hospital_profile):\n",
    "    \"\"\"Calculate score based on dynamic hospital affinities.\"\"\"\n",
    "    score = 0.0\n",
    "    affinities = hospital_profile['affinities']\n",
    "    \n",
    "    for code, weight in patient_weights.items():\n",
    "        if code in affinities:\n",
    "            score += weight * affinities[code] # High boost for specialty match\n",
    "        else:\n",
    "            score += weight * 0.1 # Low baseline for general matching\n",
    "\n",
    "    # Add randomness (¬±15%)\n",
    "    return score * random.uniform(0.85, 1.15)\n",
    "\n",
    "def get_capacities(total_patients, profiles):\n",
    "    \"\"\"Dynamic capacity calculation based on hospital sizes.\"\"\"\n",
    "    targets = {}\n",
    "    weights = {'large': 0.4, 'medium': 0.25, 'small': 0.1}\n",
    "    \n",
    "    # Calculate total weight shares\n",
    "    total_share = sum(weights[p['size']] for p in profiles.values())\n",
    "    \n",
    "    for h_id, p in profiles.items():\n",
    "        share = weights[p['size']] / total_share\n",
    "        targets[h_id] = int(total_patients * share)\n",
    "        \n",
    "    # Adjust remainder\n",
    "    current_total = sum(targets.values())\n",
    "    diff = total_patients - current_total\n",
    "    if diff != 0:\n",
    "        h_keys = list(targets.keys())\n",
    "        for i in range(abs(diff)):\n",
    "            targets[h_keys[i % len(h_keys)]] += 1 if diff > 0 else -1\n",
    "            \n",
    "    return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Assignment & Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: ASSIGNING PATIENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_patients = len(patient_data)\n",
    "targets = get_capacities(total_patients, HOSPITAL_PROFILES)\n",
    "hospital_counts = defaultdict(int)\n",
    "assignments = {}\n",
    "\n",
    "# 1. Calculate Scores\n",
    "print(\"‚öôÔ∏è  Scoring patient affinities...\")\n",
    "patient_scores = {}\n",
    "for p_id, data in patient_data.items():\n",
    "    scores = {}\n",
    "    for h_id, profile in HOSPITAL_PROFILES.items():\n",
    "        scores[h_id] = calculate_affinity_score(data['weights'], profile)\n",
    "    patient_scores[p_id] = scores\n",
    "\n",
    "# 2. Assign\n",
    "print(\"‚öôÔ∏è  Assigning to hospitals...\")\n",
    "p_ids = list(patient_data.keys())\n",
    "random.shuffle(p_ids)\n",
    "\n",
    "for p_id in tqdm(p_ids, desc=\"Assigning\"):\n",
    "    scores = patient_scores[p_id]\n",
    "    \n",
    "    # Filter out full hospitals\n",
    "    available = [h for h in HOSPITAL_PROFILES if hospital_counts[h] < targets[h]]\n",
    "    if not available:\n",
    "        available = [max(targets.keys(), key=lambda h: targets[h] - hospital_counts[h])]\n",
    "        \n",
    "    # Probabilistic selection based on score\n",
    "    available_scores = {h: scores[h] for h in available}\n",
    "    total_score = sum(available_scores.values())\n",
    "    \n",
    "    if total_score > 0:\n",
    "        probs = {h: s/total_score for h, s in available_scores.items()}\n",
    "    else:\n",
    "        probs = {h: 1/len(available) for h in available}\n",
    "        \n",
    "    choice = np.random.choice(list(probs.keys()), p=list(probs.values()))\n",
    "    assignments[p_id] = choice\n",
    "    hospital_counts[choice] += 1\n",
    "\n",
    "# 3. Copy Files\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: DISTRIBUTING FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare Dirs\n",
    "if os.path.exists(DEST_DIR):\n",
    "    shutil.rmtree(DEST_DIR) # Clean start\n",
    "os.makedirs(DEST_DIR)\n",
    "\n",
    "for h_id in HOSPITAL_PROFILES:\n",
    "    os.makedirs(os.path.join(DEST_DIR, h_id))\n",
    "\n",
    "# Copy\n",
    "files_copied = 0\n",
    "for p_id, h_id in tqdm(assignments.items(), desc=\"Copying\"):\n",
    "    src = os.path.join(SOURCE_DIR, patient_data[p_id]['filename'])\n",
    "    dst = os.path.join(DEST_DIR, h_id, patient_data[p_id]['filename'])\n",
    "    try:\n",
    "        shutil.copy2(src, dst)\n",
    "        files_copied += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {p_id}: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Distributed {files_copied} files across {NUM_HOSPITALS} hospitals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for h_id in sorted(HOSPITAL_PROFILES.keys()):\n",
    "    count = hospital_counts[h_id]\n",
    "    prof = HOSPITAL_PROFILES[h_id]\n",
    "    \n",
    "    # Get actual top conditions in this hospital\n",
    "    h_patients = [p for p, h in assignments.items() if h == h_id]\n",
    "    cond_counts = Counter()\n",
    "    for p in h_patients:\n",
    "        for c, w in patient_data[p]['weights'].items():\n",
    "            cond_counts[c] += 1\n",
    "            \n",
    "    top_3 = [condition_names.get(c, c)[:25] for c, _ in cond_counts.most_common(3)]\n",
    "    \n",
    "    summary.append({\n",
    "        'Hospital': h_id,\n",
    "        'Size': prof['size'].upper(),\n",
    "        'Patients': count,\n",
    "        'Specialization': prof['specialization_name'],\n",
    "        'Top Observed Conditions': \", \".join(top_3)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL HOSPITAL DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
